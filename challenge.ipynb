{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Preprocessing and Pipeline libraries\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import svm\n",
    "\n",
    "# import flask\n",
    "from flask import Flask, request, jsonify, redirect, url_for, flash\n",
    "from sklearn.externals import joblib\n",
    "import traceback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading training data...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLoading training data...\")\n",
    "# load training data\n",
    "train_data = pd.read_csv(\"data/peerLoanTraining.csv\", engine='python', header=0)\n",
    "\n",
    "# Separate out X and y\n",
    "X_train = train_data.loc[:, train_data.columns != 'is_late']\n",
    "y_train = train_data['is_late']\n",
    "\n",
    "\n",
    "# load test data\n",
    "test_data = pd.read_csv(\"data/peerLoanTest.csv\", engine='python', header=0)\n",
    "\n",
    "# Separate out X and y\n",
    "X_test = test_data.loc[:, test_data.columns != 'is_late']\n",
    "y_test = test_data['is_late']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Steps\n",
    "numeric_features = ['loan_amnt',\n",
    "                    'int_rate', 'annual_inc', 'revol_util',\n",
    "                    'dti', 'delinq_2yrs'\n",
    "                   ]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ])\n",
    "\n",
    "categorical_features = ['purpose','grade', 'emp_length', 'home_ownership']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine preprocessing with classifier\n",
    "latePaymentsModel = make_pipeline(preprocess, RandomForestClassifier(n_estimators = 10, random_state = 1, bootstrap = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('columntransformer', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('num', Pipeline(memory=None,\n",
       "     steps=[('imputer', SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "       strategy='median', ...imators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the pipeline to the training data (fit is for both the preprocessing and the classifier)\n",
    "print(\"\\nTraining model ...\")\n",
    "latePaymentsModel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model ...\n",
      "\n",
      "Loading saved model to make example predictions...\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model as a pickle file\n",
    "print(\"\\nSaving model ...\")\n",
    "file = open('latePaymentsModel.pkl', 'wb')\n",
    "pickle.dump(latePaymentsModel, file)\n",
    "file.close()\n",
    "\n",
    "# load the pickled model\n",
    "print(\"\\nLoading saved model to make example predictions...\")\n",
    "pickledModel = pickle.load(open('latePaymentsModel.pkl','rb'))\n",
    "\n",
    "# # Save the data columns from training\n",
    "# model_columns = list(X_train.columns)\n",
    "# print(\"\\nSaving model columns ...\")\n",
    "# file = open('model_columns.pkl','wb')\n",
    "# pickle.dump(model_columns, file)\n",
    "# file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting class probabilities for likely on-time payer:\n",
      "[[1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction for a likely on time payer\n",
    "payOnTimePrediction = {\n",
    "    'loan_amnt': [100],\n",
    "    'int_rate': [0.02039],\n",
    "    'purpose': ['credit_card'],\n",
    "    'grade': ['A'],\n",
    "    'annual_inc': [80000.00],\n",
    "    'revol_util': [0.05],\n",
    "    'emp_length': ['10+ years'],\n",
    "    'dti': [1.46],\n",
    "    'delinq_2yrs': [0],\n",
    "    'home_ownership': ['RENT']\n",
    "    }\n",
    "payOnTimePredictionDf = pd.DataFrame.from_dict(payOnTimePrediction)\n",
    "\n",
    "print(\"\\nPredicting class probabilities for likely on-time payer:\")\n",
    "print(pickledModel.predict_proba(payOnTimePredictionDf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting class probabilities for a likely late payer:\n",
      "[[0.5 0.5]]\n"
     ]
    }
   ],
   "source": [
    "# Prediction for a likely late payer\n",
    "payLatePrediction = {\n",
    "    'loan_amnt': [10000],\n",
    "    'int_rate': [0.6],\n",
    "    'purpose': ['credit_card'],\n",
    "    'grade': ['D'],\n",
    "    'annual_inc': [45000.00],\n",
    "    'revol_util': [0.85],\n",
    "    'emp_length': ['1 year'],\n",
    "    'dti': [42.00],\n",
    "    'delinq_2yrs': [4],\n",
    "    'home_ownership': ['RENT']\n",
    "    }\n",
    "payLatePredictionDf = pd.DataFrame.from_dict(payLatePrediction)\n",
    "\n",
    "print(\"\\nPredicting class probabilities for a likely late payer:\")\n",
    "print(pickledModel.predict_proba(payLatePredictionDf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting class probabilities for the test data set:\n",
      "[[0.9 0.1]\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " ...\n",
      " [1.  0. ]\n",
      " [1.  0. ]\n",
      " [1.  0. ]]\n",
      "Accuracy:\n",
      "0.9861172000584539\n",
      "confusion matrix is [[6748    0]\n",
      " [  95    0]]\n"
     ]
    }
   ],
   "source": [
    "# Predict class probabilities for a set of records using the test set\n",
    "print(\"\\nPredicting class probabilities for the test data set:\")\n",
    "print(pickledModel.predict_proba(X_test))\n",
    "\n",
    "# Printing accuracy\n",
    "print(\"Accuracy:\\n%s\" % accuracy_score(y_test, pickledModel.predict(X_test)))\n",
    "\n",
    "# Printing Confusion Matrix\n",
    "cm = confusion_matrix(y_test, pickledModel.predict(X_test))\n",
    "print(\"confusion matrix is %s\"%cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
